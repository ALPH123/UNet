{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "plastic-depth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/hwang/anaconda3/lib/python3.7/site-packages/')\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import nibabel\n",
    "import math\n",
    "# import texture\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, Input, Lambda, Reshape, AveragePooling2D, BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.applications.resnet50 import ResNet50, decode_predictions\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.callbacks import EarlyStopping, LambdaCallback, ModelCheckpoint \n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras_unet.utils import plot_imgs, get_augmented, plot_segm_history\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance \n",
    "from keras_unet.models import custom_unet\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "serious-services",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.config.list_physical_devices('GPU')\n",
    "from tensorflow.python.client import device_lib\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "every-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.set_visible_devices(physical_devices[0:1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "radio-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete .DS_Store file in each folder \n",
    "\n",
    "# resample\n",
    "            \n",
    "resampath = '/home/gpuadmin/anaconda3/envs/py380/Work/Segmentation_UNet/T1NORM_RESAMPLE/HC/Train/'\n",
    "resampfile = os.listdir(resampath)\n",
    "resampfile.sort()\n",
    "num_seg = len(resampfile)\n",
    "count_seg = 0\n",
    "for item_resamp in os.listdir(resampath):\n",
    "    current_resamp = os.path.basename(item_resamp)\n",
    "    if current_resamp == '.DS_Store':\n",
    "        fullpath = os.path.join(resampath,current_resamp)\n",
    "        os.remove(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ancient-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature for deep learning (3D): img\n",
    "\n",
    "resampath = '/home/gpuadmin/anaconda3/envs/py380/Work/Segmentation_UNet/T1NORM_RESAMPLE/HC/Train/'\n",
    "resampfile = os.listdir(resampath)\n",
    "resampfile.sort()\n",
    "num_img = len(resampfile)\n",
    "\n",
    "first = sitk.ReadImage(os.path.join(resampath,resampfile[0]))\n",
    "feature = sitk.GetArrayFromImage(first)\n",
    "\n",
    "feature_reshape = feature.transpose(1,2,0)\n",
    "\n",
    "for n in range(len(os.listdir(resampath))):\n",
    "\n",
    "    i = sitk.ReadImage(os.path.join(resampath,resampfile[n]))\n",
    "    j = sitk.GetArrayFromImage(i)\n",
    "    j_reshape = j.transpose(1,2,0)\n",
    "    feature_reshape = np.dstack((feature_reshape, j_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bottom-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete .DS_Store file in each folder \n",
    "\n",
    "# resample\n",
    "            \n",
    "resampath = '/home/gpuadmin/anaconda3/envs/py380/Work/Segmentation_UNet/ROI_RAD_RESAMPLE/HC/Train/'\n",
    "resampfile = os.listdir(resampath)\n",
    "resampfile.sort()\n",
    "num_seg = len(resampfile)\n",
    "count_seg = 0\n",
    "for item_resamp in os.listdir(resampath):\n",
    "    current_resamp = os.path.basename(item_resamp)\n",
    "    if current_resamp == '.DS_Store':\n",
    "        fullpath = os.path.join(resampath,current_resamp)\n",
    "        os.remove(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "periodic-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature for deep learning (3D): mask\n",
    "\n",
    "resampath = '/home/gpuadmin/anaconda3/envs/py380/Work/Segmentation_UNet/ROI_RAD_RESAMPLE/HC/Train/'\n",
    "resampfile = os.listdir(resampath)\n",
    "resampfile.sort()\n",
    "num_img = len(resampfile)\n",
    "\n",
    "first = sitk.ReadImage(os.path.join(resampath,resampfile[0]))\n",
    "mask = sitk.GetArrayFromImage(first)\n",
    "\n",
    "mask_reshape = mask.transpose(1,2,0)\n",
    "\n",
    "for n in range(len(os.listdir(resampath))):\n",
    "\n",
    "    i = sitk.ReadImage(os.path.join(resampath,resampfile[n]))\n",
    "    j = sitk.GetArrayFromImage(i)\n",
    "    j_reshape = j.transpose(1,2,0)\n",
    "    mask_reshape = np.dstack((mask_reshape, j_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sought-register",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(528, 528, 192)\n",
      "(528, 528, 192)\n"
     ]
    }
   ],
   "source": [
    "# Extract slices with masks identified from a training set \n",
    "\n",
    "mask_valid = np.zeros((feature_reshape.shape[0], feature_reshape.shape[1]))\n",
    "feature_valid = np.zeros((feature_reshape.shape[0], feature_reshape.shape[1]))\n",
    "\n",
    "for n in range(feature_reshape.shape[2]):\n",
    "\n",
    "    mask_slice = mask_reshape[:,:,n]\n",
    "    feature_slice = feature_reshape[:,:,n]\n",
    "    \n",
    "    if (len(np.unique(mask_slice)) > 1): # only if mask is identified by a radiologist \n",
    "        \n",
    "        mask_valid = np.dstack((mask_valid, mask_slice))\n",
    "        feature_valid = np.dstack((feature_valid, feature_slice))\n",
    "        \n",
    "mask_valid = mask_valid[:,:,1:]\n",
    "feature_valid = feature_valid[:,:,1:]\n",
    "\n",
    "print(mask_valid.shape)\n",
    "print(feature_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "contrary-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature_valid\n",
    "feature.shape\n",
    "maxval = np.amax(feature)\n",
    "feature_norm = feature/maxval\n",
    "feature_temp = feature_norm.transpose(2,0,1)\n",
    "feature_final = feature_temp.reshape((feature_temp.shape[0],feature_temp.shape[1],feature_temp.shape[2],1))\n",
    "feature_final.shape\n",
    "\n",
    "mask = mask_valid\n",
    "mask_final = mask.transpose(2,0,1)\n",
    "mask_final = mask_final.reshape((mask_final.shape[0],mask_final.shape[1],mask_final.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "induced-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_final\n",
    "y_train = mask_final \n",
    "\n",
    "# feature_final = feature_reshape = []\n",
    "# mask_final = mask_reshape = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "revised-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete .DS_Store file in each folder \n",
    "\n",
    "# resample\n",
    "            \n",
    "resampath = '/home/gpuadmin/anaconda3/envs/py380/Work/Segmentation_UNet/T1NORM_RESAMPLE/HC/Test/'\n",
    "resampfile = os.listdir(resampath)\n",
    "resampfile.sort()\n",
    "num_seg = len(resampfile)\n",
    "count_seg = 0\n",
    "for item_resamp in os.listdir(resampath):\n",
    "    current_resamp = os.path.basename(item_resamp)\n",
    "    if current_resamp == '.DS_Store':\n",
    "        fullpath = os.path.join(resampath,current_resamp)\n",
    "        os.remove(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "operating-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature for deep learning (3D): img\n",
    "\n",
    "resampath = '/home/gpuadmin/anaconda3/envs/py380/Work/Segmentation_UNet/T1NORM_RESAMPLE/HC/Test/'\n",
    "resampfile = os.listdir(resampath)\n",
    "resampfile.sort()\n",
    "num_img = len(resampfile)\n",
    "\n",
    "first = sitk.ReadImage(os.path.join(resampath,resampfile[0]))\n",
    "feature = sitk.GetArrayFromImage(first)\n",
    "\n",
    "feature_reshape = feature.transpose(1,2,0)\n",
    "\n",
    "for n in range(len(os.listdir(resampath))):\n",
    "\n",
    "    i = sitk.ReadImage(os.path.join(resampath,resampfile[n]))\n",
    "    j = sitk.GetArrayFromImage(i)\n",
    "    j_reshape = j.transpose(1,2,0)\n",
    "    feature_reshape = np.dstack((feature_reshape, j_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comfortable-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete .DS_Store file in each folder \n",
    "\n",
    "# resample\n",
    "            \n",
    "resampath = '/home/gpuadmin/anaconda3/envs/py380/Work/Segmentation_UNet/ROI_RAD_RESAMPLE/HC/Test/'\n",
    "resampfile = os.listdir(resampath)\n",
    "resampfile.sort()\n",
    "num_seg = len(resampfile)\n",
    "count_seg = 0\n",
    "for item_resamp in os.listdir(resampath):\n",
    "    current_resamp = os.path.basename(item_resamp)\n",
    "    if current_resamp == '.DS_Store':\n",
    "        fullpath = os.path.join(resampath,current_resamp)\n",
    "        os.remove(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "compound-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature for deep learning (3D): mask\n",
    "\n",
    "resampath = '/home/gpuadmin/anaconda3/envs/py380/Work/Segmentation_UNet/ROI_RAD_RESAMPLE/HC/Test/'\n",
    "resampfile = os.listdir(resampath)\n",
    "resampfile.sort()\n",
    "num_img = len(resampfile)\n",
    "\n",
    "first = sitk.ReadImage(os.path.join(resampath,resampfile[0]))\n",
    "mask = sitk.GetArrayFromImage(first)\n",
    "\n",
    "mask_reshape = mask.transpose(1,2,0)\n",
    "\n",
    "for n in range(len(os.listdir(resampath))):\n",
    "\n",
    "    i = sitk.ReadImage(os.path.join(resampath,resampfile[n]))\n",
    "    j = sitk.GetArrayFromImage(i)\n",
    "    j_reshape = j.transpose(1,2,0)\n",
    "    mask_reshape = np.dstack((mask_reshape, j_reshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "minimal-tomato",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(528, 528, 187)\n",
      "(528, 528, 187)\n"
     ]
    }
   ],
   "source": [
    "# Extract slices with masks identified from a training set \n",
    "\n",
    "mask_valid = np.zeros((feature_reshape.shape[0], feature_reshape.shape[1]))\n",
    "feature_valid = np.zeros((feature_reshape.shape[0], feature_reshape.shape[1]))\n",
    "\n",
    "for n in range(feature_reshape.shape[2]):\n",
    "\n",
    "    mask_slice = mask_reshape[:,:,n]\n",
    "    feature_slice = feature_reshape[:,:,n]\n",
    "    \n",
    "    if (len(np.unique(mask_slice)) > 1): # only if mask is identified by a radiologist \n",
    "        \n",
    "        mask_valid = np.dstack((mask_valid, mask_slice))\n",
    "        feature_valid = np.dstack((feature_valid, feature_slice))\n",
    "        \n",
    "mask_valid = mask_valid[:,:,1:]\n",
    "feature_valid = feature_valid[:,:,1:]\n",
    "\n",
    "print(mask_valid.shape)\n",
    "print(feature_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "color-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature_valid\n",
    "feature.shape\n",
    "maxval = np.amax(feature)\n",
    "feature_norm = feature/maxval\n",
    "feature_temp = feature_norm.transpose(2,0,1)\n",
    "feature_final = feature_temp.reshape((feature_temp.shape[0],feature_temp.shape[1],feature_temp.shape[2],1))\n",
    "feature_final.shape\n",
    "\n",
    "mask = mask_valid\n",
    "mask_final = mask.transpose(2,0,1)\n",
    "mask_final = mask_final.reshape((mask_final.shape[0],mask_final.shape[1],mask_final.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "capital-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = feature_final\n",
    "y_test = mask_final \n",
    "\n",
    "# feature_final = feature_reshape = []\n",
    "# mask_final = mask_reshape = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pointed-timer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 528, 528, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 528, 528, 32) 288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 528, 528, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d (SpatialDropo (None, 528, 528, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 528, 528, 32) 9216        spatial_dropout2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 528, 528, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 264, 264, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 264, 264, 64) 18432       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 264, 264, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 264, 264, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 264, 264, 64) 36864       spatial_dropout2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 264, 264, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 132, 132, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 132, 132, 128 73728       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 132, 132, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_2 (SpatialDro (None, 132, 132, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 132, 132, 128 147456      spatial_dropout2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 132, 132, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 66, 66, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 66, 66, 256)  294912      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 66, 66, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_3 (SpatialDro (None, 66, 66, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 66, 66, 256)  589824      spatial_dropout2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 66, 66, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 33, 33, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 33, 33, 512)  1179648     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 33, 33, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_4 (SpatialDro (None, 33, 33, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 33, 33, 512)  2359296     spatial_dropout2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 33, 33, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 66, 66, 256)  524544      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 66, 66, 512)  0           conv2d_transpose[0][0]           \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 66, 66, 256)  1179648     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 66, 66, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 66, 66, 256)  589824      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 66, 66, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 132, 132, 128 131200      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 132, 132, 256 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 132, 132, 128 294912      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 132, 132, 128 512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 132, 132, 128 147456      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 132, 132, 128 512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 264, 264, 64) 32832       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 264, 264, 128 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 264, 264, 64) 73728       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 264, 264, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 264, 264, 64) 36864       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 264, 264, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 528, 528, 32) 8224        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 528, 528, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 528, 528, 32) 18432       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 528, 528, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 528, 528, 32) 9216        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 528, 528, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 528, 528, 1)  33          batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 7,768,353\n",
      "Trainable params: 7,762,465\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_gen = get_augmented(X_train, y_train, batch_size = 32, data_gen_args = dict(rotation_range = 5., width_shift_range = 0.05, height_shift_range = 0.05, shear_range = 40, zoom_range = 0.2, horizontal_flip = True, vertical_flip = True, fill_mode = 'constant'))\n",
    "sample_batch = next(train_gen)\n",
    "xx, yy = sample_batch\n",
    "input_shape = X_train[0].shape\n",
    "\n",
    "model = custom_unet(input_shape, filters = 32, use_batch_norm = True, dropout = 0.3, dropout_change_per_layer = 0.0, num_layers = 4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "awful-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model_filename = '2d_unet_BM.h5'\n",
    "# es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1)\n",
    "callback_checkpoint = ModelCheckpoint(model_filename, verbose = 1, monitor = 'val_loss', save_best_only=True)\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = [iou, iou_thresholded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "yellow-seafood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,64,264,264] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/conv2d_3/Conv2D (defined at <ipython-input-20-42f5ca614be6>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_4570]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-42f5ca614be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcallback_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py380/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1847\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1848\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py380/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py380/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py380/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py380/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py380/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/py380/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py380/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,64,264,264] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/conv2d_3/Conv2D (defined at <ipython-input-20-42f5ca614be6>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_4570]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, steps_per_epoch = len(y_train)//batch_size, epochs = 10, validation_data = (X_test, y_test), callbacks = [callback_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_filename)\n",
    "model.load_weights(model_filename)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=19)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py380] *",
   "language": "python",
   "name": "conda-env-py380-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
